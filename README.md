# ğŸ§  Tutorial de EspaÃ§o Latente: Autoencoders e VAEs

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Made with â¤ï¸](https://img.shields.io/badge/Made%20with-â¤ï¸-red.svg)](https://github.com/itamar15/latent-space-tutorial)

> ğŸ“š Material didÃ¡tico completo sobre espaÃ§o latente, autoencoders e Variational Autoencoders (VAEs), desenvolvido para aulas de IA Generativa e Aprendizado Profundo.

## ğŸ¯ Sobre o Projeto

Este repositÃ³rio contÃ©m material didÃ¡tico completo para ensinar os conceitos de **espaÃ§o latente**, **autoencoders** e **VAEs** (Variational Autoencoders). Foi desenvolvido com foco em clareza, visualizaÃ§Ãµes interativas e exemplos prÃ¡ticos que podem ser usados diretamente em sala de aula.

### âœ¨ Destaques

- ğŸ“Š **6 Notebooks Jupyter** progressivos e interativos
- ğŸ¨ **VisualizaÃ§Ãµes ricas** para exploraÃ§Ã£o do espaÃ§o latente
- ğŸ”¬ **Experimentos comparativos** (Beta-VAE)
- ğŸ› ï¸ **CÃ³digo modular** e reutilizÃ¡vel
- ğŸ“– **DocumentaÃ§Ã£o completa** com fundamentos matemÃ¡ticos
- ğŸ® **Interface interativa** para exploraÃ§Ã£o
- âœ… **Testes unitÃ¡rios** incluÃ­dos

## ğŸ“‹ ConteÃºdo

### ğŸ““ Notebooks

1. **[Analogia: O Mapa do Tesouro](notebooks/01_analogia_espaco_latente.ipynb)** - IntroduÃ§Ã£o conceitual visual
2. **[Autoencoder BÃ¡sico](notebooks/02_autoencoder_basico.ipynb)** - ImplementaÃ§Ã£o e compressÃ£o 784â†’2
3. **[VAE Explicativo](notebooks/03_vae_explicativo.ipynb)** - EspaÃ§o latente probabilÃ­stico
4. **[Experimento Beta-VAE](notebooks/04_beta_vae_experimento.ipynb)** - AnÃ¡lise comparativa de Î²
5. **[ExploraÃ§Ã£o Interativa](notebooks/05_exploracao_interativa.ipynb)** - Interface para navegar no espaÃ§o latente
6. **[Exemplos AvanÃ§ados](notebooks/06_exemplos_avancados.ipynb)** - AplicaÃ§Ãµes prÃ¡ticas

### ğŸ“š DocumentaÃ§Ã£o

- [Conceitos Fundamentais](docs/conceitos.md)
- [Fundamentos MatemÃ¡ticos](docs/matematica.md)
- [ReferÃªncias e Leituras](docs/referencias.md)
- [Tutoriais Passo a Passo](docs/tutoriais/)

### ğŸ”§ MÃ³dulos Python

```
src/
â”œâ”€â”€ models/          # ImplementaÃ§Ãµes de Autoencoder, VAE, Beta-VAE
â”œâ”€â”€ utils/           # Utilidades para dados, visualizaÃ§Ã£o e treinamento
â””â”€â”€ experiments/     # Experimentos e anÃ¡lises
```

## ğŸš€ InstalaÃ§Ã£o RÃ¡pida

### PrÃ©-requisitos

- Python 3.8 ou superior
- pip ou conda

### OpÃ§Ã£o 1: pip

```bash
# Clone o repositÃ³rio
git clone https://github.com/itamar15/latent-space-tutorial.git
cd latent-space-tutorial

# Crie um ambiente virtual
python -m venv venv
source venv/bin/activate  # No Windows: venv\Scripts\activate

# Instale as dependÃªncias
pip install -r requirements.txt

# Instale o pacote em modo desenvolvimento
pip install -e .
```

### OpÃ§Ã£o 2: conda

```bash
# Clone o repositÃ³rio
git clone https://github.com/itamar15/latent-space-tutorial.git
cd latent-space-tutorial

# Crie o ambiente
conda env create -f environment.yml
conda activate latent-space

# Instale o pacote
pip install -e .
```

## ğŸ“ Guia RÃ¡pido para Professores

### Plano de Aula Sugerido (90 minutos)

| Tempo | Atividade | Notebook |
|-------|-----------|----------|
| 0-15 min | IntroduÃ§Ã£o conceitual | `01_analogia_espaco_latente.ipynb` |
| 15-35 min | Autoencoder prÃ¡tico | `02_autoencoder_basico.ipynb` |
| 35-40 min | â˜• Pausa | - |
| 40-65 min | VAE e probabilidade | `03_vae_explicativo.ipynb` |
| 65-80 min | Experimento Beta-VAE | `04_beta_vae_experimento.ipynb` |
| 80-90 min | ExploraÃ§Ã£o livre | `05_exploracao_interativa.ipynb` |

### Material Complementar

- ğŸ“Š Slides (em `docs/slides/`)
- ğŸ¯ ExercÃ­cios prÃ¡ticos
- ğŸ“ Gabaritos de resoluÃ§Ã£o

## ğŸ’» Uso RÃ¡pido

### Exemplo 1: Treinar um Autoencoder

```python
from src.models import Autoencoder
from src.utils import load_mnist, train_model, visualize_latent_space

# Carregar dados
train_loader, test_loader = load_mnist(batch_size=128)

# Criar modelo
model = Autoencoder(input_dim=784, latent_dim=2)

# Treinar
train_model(model, train_loader, epochs=10)

# Visualizar espaÃ§o latente
visualize_latent_space(model, test_loader)
```

### Exemplo 2: Treinar um VAE

```python
from src.models import VAE
from src.utils import load_mnist, train_vae, plot_vae_results

# Carregar dados
train_loader, test_loader = load_mnist(batch_size=128)

# Criar VAE
vae = VAE(input_dim=784, latent_dim=2)

# Treinar
train_vae(vae, train_loader, epochs=20)

# Visualizar resultados
plot_vae_results(vae, test_loader)
```

### Exemplo 3: Explorar EspaÃ§o Latente

```python
from src.experiments import LatentExplorer

# Criar explorador
explorer = LatentExplorer(vae)

# Explorar dimensÃ£o especÃ­fica
explorer.explore_dimension(dim=0, n_steps=10)

# Interpolar entre pontos
explorer.interpolate(point_a=[1.0, 1.0], point_b=[-1.0, -1.0], steps=10)

# Criar caminho no espaÃ§o latente
explorer.create_path([[0, 0], [2, 1], [1, -2]], steps_between=5)
```

## ğŸ“Š Resultados Esperados

### Autoencoder
- CompressÃ£o: 784 â†’ 2 dimensÃµes (~392x)
- ReconstruÃ§Ã£o: MSE < 0.05
- Tempo de treinamento: ~2 min (GPU) / ~10 min (CPU)

### VAE
- GeraÃ§Ã£o de novas amostras: âœ…
- InterpolaÃ§Ã£o suave: âœ…
- EspaÃ§o latente contÃ­nuo: âœ…

## ğŸ”¬ Experimentos IncluÃ­dos

### 1. ComparaÃ§Ã£o Beta-VAE

```python
from src.experiments import BetaVAEComparison

experiment = BetaVAEComparison()
experiment.compare_betas([0.5, 1.0, 2.0, 4.0])
```

**Resultado esperado:** 
- Î² baixo â†’ melhor reconstruÃ§Ã£o, espaÃ§o latente menos estruturado
- Î² alto â†’ pior reconstruÃ§Ã£o, melhor separaÃ§Ã£o de conceitos

### 2. AnÃ¡lise de Disentanglement

```python
from src.experiments import analyze_disentanglement

results = analyze_disentanglement(vae, test_loader)
print(f"Score: {results['score']:.3f}")
```

## ğŸ§ª Executar Testes

```bash
# Todos os testes
pytest tests/

# Testes especÃ­ficos
pytest tests/test_models.py
pytest tests/test_utils.py

# Com cobertura
pytest --cov=src tests/
```

## ğŸ“– DocumentaÃ§Ã£o Adicional

- [Conceitos Fundamentais](docs/conceitos.md) - O que Ã© espaÃ§o latente?
- [MatemÃ¡tica dos VAEs](docs/matematica.md) - DerivaÃ§Ãµes e provas
- [Tutoriais Detalhados](docs/tutoriais/) - Guias passo a passo
- [ReferÃªncias](docs/referencias.md) - Papers e recursos

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

Veja [CONTRIBUTING.md](CONTRIBUTING.md) para mais detalhes.

## ğŸ“ CitaÃ§Ã£o

Se vocÃª usar este material em suas aulas ou pesquisas, por favor cite:

```bibtex
@misc{latent_space_tutorial,
  author = {Profa. Itamar},
  title = {Tutorial de EspaÃ§o Latente: Autoencoders e VAEs},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/itamar15/latent-space-tutorial}
}
```

## ğŸ‘¥ Autora

- **Profa. Itamar** - Professora de CiÃªncia da ComputaÃ§Ã£o, UTFPR Campus Ponta Grossa - [GitHub](https://github.com/itamar15)

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ™ Agradecimentos

- Dataset MNIST (Yann LeCun et al.)
- PyTorch team
- Comunidade de Machine Learning
- Meus alunos da UTFPR

## ğŸ“¬ Contato

Profa. Itamar - UTFPR Campus Ponta Grossa

Link do Projeto: [https://github.com/itamar15/latent-space-tutorial](https://github.com/itamar15/latent-space-tutorial)

---

<p align="center">
  Feito com â¤ï¸ para ensino de IA Generativa
</p>

<p align="center">
  <a href="#-sobre-o-projeto">Topo</a> â€¢
  <a href="#-instalaÃ§Ã£o-rÃ¡pida">InstalaÃ§Ã£o</a> â€¢
  <a href="#-uso-rÃ¡pido">Uso</a> â€¢
  <a href="#-documentaÃ§Ã£o-adicional">Docs</a> â€¢
  <a href="#-licenÃ§a">LicenÃ§a</a>
</p>
