{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Exemplos Avan√ßados e Aplica√ß√µes\n",
    "\n",
    "**Tutorial de Espa√ßo Latente - Notebook 6**\n",
    "\n",
    "## üéØ Objetivos\n",
    "- T√©cnicas avan√ßadas de treinamento\n",
    "- Aplica√ß√µes pr√°ticas de VAEs\n",
    "- Dicas de debugging e otimiza√ß√£o\n",
    "- Extens√µes e pr√≥ximos passos\n",
    "- Integrando tudo que aprendemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.models.vae import VAE\n",
    "from src.models.beta_vae import BetaVAE, AnnealedBetaVAE\n",
    "from src.utils.data_loader import load_mnist\n",
    "from src.utils.training import train_vae, EarlyStopping\n",
    "from src.utils.visualization import *\n",
    "from src.experiments import LatentExplorer, BetaVAEComparison\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Aplica√ß√£o 1: Detec√ß√£o de Anomalias\n",
    "\n",
    "VAEs podem detectar imagens \"an√¥malas\" atrav√©s do erro de reconstru√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega dados\n",
    "train_loader, val_loader, test_loader = load_mnist(batch_size=128)\n",
    "\n",
    "# Treina VAE\n",
    "vae = VAE(input_dim=784, latent_dim=10, hidden_dims=[512, 256])\n",
    "\n",
    "history = train_vae(\n",
    "    model=vae,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=20,\n",
    "    device=DEVICE,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ VAE trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula reconstruction error para todo test set\n",
    "vae.eval()\n",
    "reconstruction_errors = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, labels in test_loader:\n",
    "        data = data.view(-1, 784).to(DEVICE)\n",
    "        recon, mu, logvar, z = vae(data)\n",
    "        \n",
    "        # Erro por amostra\n",
    "        errors = ((data - recon) ** 2).sum(dim=1).cpu().numpy()\n",
    "        reconstruction_errors.extend(errors)\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "reconstruction_errors = np.array(reconstruction_errors)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Visualiza distribui√ß√£o de erros por d√≠gito\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for digit in range(10):\n",
    "    mask = all_labels == digit\n",
    "    errors_digit = reconstruction_errors[mask]\n",
    "    ax.hist(errors_digit, bins=50, alpha=0.5, label=f'Digit {digit}')\n",
    "\n",
    "ax.set_xlabel('Reconstruction Error', fontweight='bold')\n",
    "ax.set_ylabel('Count', fontweight='bold')\n",
    "ax.set_title('Reconstruction Error Distribution by Digit', fontweight='bold', fontsize=14)\n",
    "ax.legend(ncol=5)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Encontra anomalias (top 1% maior erro)\n",
    "threshold = np.percentile(reconstruction_errors, 99)\n",
    "anomaly_indices = np.where(reconstruction_errors > threshold)[0]\n",
    "\n",
    "print(f\"\\nüîç Anomaly Detection:\")\n",
    "print(f\"  Threshold (99th percentile): {threshold:.2f}\")\n",
    "print(f\"  Number of anomalies: {len(anomaly_indices)}\")\n",
    "print(f\"  Anomaly rate: {100*len(anomaly_indices)/len(reconstruction_errors):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza anomalias\n",
    "data_all = torch.cat([d for d, _ in test_loader]).view(-1, 784)\n",
    "\n",
    "fig, axes = plt.subplots(2, 10, figsize=(15, 3))\n",
    "\n",
    "for i in range(10):\n",
    "    idx = anomaly_indices[i]\n",
    "    img = data_all[idx].view(28, 28)\n",
    "    error = reconstruction_errors[idx]\n",
    "    label = all_labels[idx]\n",
    "    \n",
    "    axes[0, i].imshow(img, cmap='gray')\n",
    "    axes[0, i].set_title(f'Label: {label}\\nError: {error:.1f}', fontsize=9)\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Reconstru√ß√£o\n",
    "    with torch.no_grad():\n",
    "        recon, _, _, _ = vae(data_all[idx:idx+1].to(DEVICE))\n",
    "        recon_img = recon.view(28, 28).cpu()\n",
    "    \n",
    "    axes[1, i].imshow(recon_img, cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_ylabel('Original', fontweight='bold', fontsize=11)\n",
    "        axes[1, i].set_ylabel('Recon', fontweight='bold', fontsize=11)\n",
    "\n",
    "plt.suptitle('Top 10 Anomalies (Highest Reconstruction Error)', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Imagens com alto erro podem ser:\\n  - Mal escritas\\n  - Amb√≠guas\\n  - Raras no dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Aplica√ß√£o 2: Data Augmentation\n",
    "\n",
    "Use VAE para gerar varia√ß√µes de dados existentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(vae, image, n_augmentations=5, noise_scale=0.3):\n",
    "    \"\"\"Gera varia√ß√µes de uma imagem adicionando ru√≠do no espa√ßo latente.\"\"\"\n",
    "    vae.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Encode\n",
    "        img_tensor = image.view(1, -1).to(DEVICE)\n",
    "        mu, logvar = vae.encode(img_tensor)\n",
    "        \n",
    "        augmented = []\n",
    "        for _ in range(n_augmentations):\n",
    "            # Adiciona ru√≠do gaussiano no espa√ßo latente\n",
    "            noise = torch.randn_like(mu) * noise_scale\n",
    "            z_augmented = mu + noise\n",
    "            \n",
    "            # Decode\n",
    "            aug_img = vae.decode(z_augmented)\n",
    "            augmented.append(aug_img.view(28, 28).cpu())\n",
    "    \n",
    "    return augmented\n",
    "\n",
    "# Pega uma imagem\n",
    "sample_img, sample_label = next(iter(test_loader))\n",
    "original = sample_img[0]\n",
    "\n",
    "# Gera augmenta√ß√µes\n",
    "augmented_images = augment_data(vae, original, n_augmentations=9)\n",
    "\n",
    "# Visualiza\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "\n",
    "axes[0, 0].imshow(original.squeeze(), cmap='gray')\n",
    "axes[0, 0].set_title('Original', fontweight='bold')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "for i in range(9):\n",
    "    row = (i+1) // 5\n",
    "    col = (i+1) % 5\n",
    "    axes[row, col].imshow(augmented_images[i], cmap='gray')\n",
    "    axes[row, col].set_title(f'Aug {i+1}', fontsize=10)\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.suptitle(f'Data Augmentation via Latent Space Perturbation (Label: {sample_label[0]})',\n",
    "            fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Aplica√ß√£o 3: Latent Space Interpolation Path Finding\n",
    "\n",
    "Encontra o caminho \"mais suave\" entre duas imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpola√ß√£o esf√©rica (SLERP) vs linear\n",
    "def slerp(z1, z2, t):\n",
    "    \"\"\"Spherical Linear Interpolation.\"\"\"\n",
    "    omega = torch.acos((z1 * z2).sum() / (torch.norm(z1) * torch.norm(z2)))\n",
    "    so = torch.sin(omega)\n",
    "    return torch.sin((1-t)*omega) / so * z1 + torch.sin(t*omega) / so * z2\n",
    "\n",
    "# Pega duas imagens\n",
    "img1, img2 = sample_img[0], sample_img[5]\n",
    "\n",
    "# Encode\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    mu1, _ = vae.encode(img1.view(1, -1).to(DEVICE))\n",
    "    mu2, _ = vae.encode(img2.view(1, -1).to(DEVICE))\n",
    "\n",
    "# Interpola√ß√µes\n",
    "n_steps = 10\n",
    "alphas = torch.linspace(0, 1, n_steps)\n",
    "\n",
    "linear_interp = []\n",
    "slerp_interp = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for alpha in alphas:\n",
    "        # Linear\n",
    "        z_linear = (1 - alpha) * mu1 + alpha * mu2\n",
    "        img_linear = vae.decode(z_linear).view(28, 28).cpu()\n",
    "        linear_interp.append(img_linear)\n",
    "        \n",
    "        # SLERP\n",
    "        z_slerp = slerp(mu1[0], mu2[0], alpha).unsqueeze(0)\n",
    "        img_slerp = vae.decode(z_slerp).view(28, 28).cpu()\n",
    "        slerp_interp.append(img_slerp)\n",
    "\n",
    "# Visualiza\n",
    "fig, axes = plt.subplots(2, n_steps, figsize=(15, 3))\n",
    "\n",
    "for i in range(n_steps):\n",
    "    axes[0, i].imshow(linear_interp[i], cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[0, i].set_title('Linear', fontweight='bold', loc='left')\n",
    "    \n",
    "    axes[1, i].imshow(slerp_interp[i], cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    if i == 0:\n",
    "        axes[1, i].set_title('SLERP', fontweight='bold', loc='left')\n",
    "\n",
    "plt.suptitle('Linear vs Spherical Interpolation', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß T√©cnica Avan√ßada: Scheduled Sampling\n",
    "\n",
    "Durante treinamento, gradualmente usa pr√≥prias predi√ß√µes ao inv√©s de dados reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo conceitual (n√£o implementado completamente)\n",
    "print(\"üìö Scheduled Sampling Concept:\")\n",
    "print(\"\\nEpoch 1-5: Use 100% dados reais\")\n",
    "print(\"Epoch 6-10: Use 80% dados reais, 20% reconstru√ß√µes\")\n",
    "print(\"Epoch 11-15: Use 60% dados reais, 40% reconstru√ß√µes\")\n",
    "print(\"...\")\n",
    "print(\"\\nüí° For√ßa o modelo a confiar nas pr√≥prias predi√ß√µes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üêõ Debugging: Visualizando Gradientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para plotar magnitude dos gradientes\n",
    "def plot_grad_flow(named_parameters):\n",
    "    \"\"\"Plota magnitude dos gradientes para debug.\"\"\"\n",
    "    ave_grads = []\n",
    "    max_grads = []\n",
    "    layers = []\n",
    "    \n",
    "    for n, p in named_parameters:\n",
    "        if p.requires_grad and p.grad is not None:\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean().item())\n",
    "            max_grads.append(p.grad.abs().max().item())\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.5, lw=1, color=\"c\")\n",
    "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.5, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\")\n",
    "    plt.xticks(range(0, len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "    plt.ylim(bottom=-0.001, top=max(max_grads)*1.1)\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"Gradient Magnitude\")\n",
    "    plt.title(\"Gradient Flow\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend([\"max-gradient\", \"mean-gradient\"])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Exemplo de uso\n",
    "data, _ = next(iter(train_loader))\n",
    "data = data.view(-1, 784).to(DEVICE)\n",
    "\n",
    "vae.train()\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "# Forward + backward\n",
    "from src.models.vae import vae_loss\n",
    "recon, mu, logvar, z = vae(data)\n",
    "loss_dict = vae_loss(recon, data, mu, logvar)\n",
    "loss = loss_dict['total']\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "# Plota gradientes\n",
    "plot_grad_flow(vae.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Pipeline Completo: Do Zero at√© Aplica√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Complete VAE Pipeline:\\n\")\n",
    "print(\"1. Load Data\")\n",
    "print(\"   ‚Üí load_mnist(batch_size=128)\")\n",
    "print(\"\\n2. Create Model\")\n",
    "print(\"   ‚Üí VAE(latent_dim=10, hidden_dims=[512, 256])\")\n",
    "print(\"\\n3. Train\")\n",
    "print(\"   ‚Üí train_vae(model, train_loader, val_loader, epochs=30)\")\n",
    "print(\"   ‚Üí Use early_stopping_patience=5\")\n",
    "print(\"   ‚Üí Save best model\")\n",
    "print(\"\\n4. Evaluate\")\n",
    "print(\"   ‚Üí visualize_latent_space()\")\n",
    "print(\"   ‚Üí plot_reconstructions()\")\n",
    "print(\"   ‚Üí plot_vae_results()\")\n",
    "print(\"\\n5. Apply\")\n",
    "print(\"   ‚Üí Anomaly detection\")\n",
    "print(\"   ‚Üí Data augmentation\")\n",
    "print(\"   ‚Üí Generation\")\n",
    "print(\"   ‚Üí Latent space manipulation\")\n",
    "print(\"\\n6. Experiment\")\n",
    "print(\"   ‚Üí Try different betas\")\n",
    "print(\"   ‚Üí Different latent dimensions\")\n",
    "print(\"   ‚Üí Different architectures\")\n",
    "print(\"\\n‚úÖ You now have all the tools!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Recursos Adicionais e Pr√≥ximos Passos\n",
    "\n",
    "### üìñ Leitura Recomendada\n",
    "1. **Original VAE Paper**: \"Auto-Encoding Variational Bayes\" (Kingma & Welling, 2013)\n",
    "2. **Beta-VAE**: \"Œ≤-VAE: Learning Basic Visual Concepts\" (Higgins et al., 2017)\n",
    "3. **Understanding VAEs**: Tutorial by Carl Doersch (2016)\n",
    "\n",
    "### üöÄ Extens√µes Poss√≠veis\n",
    "1. **Conditional VAE (CVAE)**: Condicionar gera√ß√£o em labels\n",
    "2. **Hierarchical VAE**: M√∫ltiplos n√≠veis latentes\n",
    "3. **VQ-VAE**: Quantiza√ß√£o vetorial\n",
    "4. **Adversarial VAE**: Combinar com GANs\n",
    "\n",
    "### üõ†Ô∏è Projetos Pr√°ticos\n",
    "1. Aplicar em outros datasets (CIFAR-10, CelebA)\n",
    "2. Style transfer no espa√ßo latente\n",
    "3. Compress√£o de imagens\n",
    "4. Detec√ß√£o de fraudes\n",
    "5. Recomenda√ß√£o de produtos\n",
    "\n",
    "### üéØ Desafios\n",
    "1. Treinar VAE com latent_dim=50\n",
    "2. Implementar CVAE\n",
    "3. Criar interface web para explora√ß√£o\n",
    "4. Aplicar em dataset pr√≥prio\n",
    "5. Comparar VAE com Autoencoder em tarefa espec√≠fica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Conclus√£o do Tutorial\n",
    "\n",
    "### O que voc√™ aprendeu:\n",
    "\n",
    "‚úÖ **Notebook 1**: Conceitos fundamentais de espa√ßo latente  \n",
    "‚úÖ **Notebook 2**: Implementa√ß√£o e treinamento de Autoencoder  \n",
    "‚úÖ **Notebook 3**: VAE e espa√ßo latente probabil√≠stico  \n",
    "‚úÖ **Notebook 4**: Beta-VAE e disentanglement  \n",
    "‚úÖ **Notebook 5**: Explora√ß√£o interativa  \n",
    "‚úÖ **Notebook 6**: Aplica√ß√µes avan√ßadas  \n",
    "\n",
    "### Habilidades Adquiridas:\n",
    "- Treinar e avaliar VAEs\n",
    "- Visualizar espa√ßos latentes\n",
    "- Gerar novas amostras\n",
    "- Detectar anomalias\n",
    "- Manipular representa√ß√µes latentes\n",
    "- Debugar modelos generativos\n",
    "\n",
    "### üåü Voc√™ est√° pronto para:\n",
    "- Aplicar VAEs em problemas reais\n",
    "- Explorar variantes mais avan√ßadas\n",
    "- Contribuir para projetos de ML\n",
    "- Ensinar outros sobre espa√ßos latentes!\n",
    "\n",
    "---\n",
    "\n",
    "## üôè Obrigado por completar este tutorial!\n",
    "\n",
    "**Professora Itamar - UTFPR**\n",
    "\n",
    "Continue explorando e experimentando! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
